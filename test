


# import streamlit as st
# from dotenv import load_dotenv
# import fitz  # PyMuPDF
# import easyocr
# from PIL import Image
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings
# from langchain_core.prompts import PromptTemplate
# from langchain.chains.summarize import load_summarize_chain
# from langchain_community.vectorstores import FAISS
# from langchain_core.vectorstores import VectorStoreRetriever
# from langchain.chains.retrieval_qa.base import RetrievalQA
# import os

# # Load environment variables
# load_dotenv()

# # Ensure Hugging Face API token is set
# HUGGINGFACEHUB_API_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")
# if not HUGGINGFACEHUB_API_TOKEN:
#     st.error("Hugging Face API token not found. Please check your .env file.")
#     st.stop()

# # Function to extract text from an image
# def extract_text_from_image(image):
#     try:
#         reader = easyocr.Reader(['en'])
#         result = reader.readtext(image, detail=0)
#         text = "\n".join(result)
#         if not text:
#             raise ValueError("No text found in the image.")
#         text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)
#         chunks = text_splitter.create_documents([text])
#         return chunks
#     except Exception as e:
#         st.error(f"Error extracting text from image: {e}")
#         return None

# # Function to extract text from a PDF
# def extract_text_from_pdf(pdf_file):
#     try:
#         text = ""
#         pdf_document = fitz.open(stream=pdf_file.read(), filetype="pdf")
#         if pdf_document.page_count == 0:
#             raise ValueError("The PDF file is empty or invalid.")
#         for page_num in range(pdf_document.page_count):
#             page = pdf_document.load_page(page_num)
#             text += page.get_text()
#         if not text:
#             raise ValueError("No text found in the PDF.")
#         text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)
#         chunks = text_splitter.create_documents([text])
#         return chunks
#     except Exception as e:
#         st.error(f"Error extracting text from PDF: {e}")
#         return None

# # Function to generate a summary using Hugging Face LLM
# def generate_summary(chunks):
#     try:
#         repo_id = "meta-llama/Meta-Llama-3-8B-Instruct"
#         llm = HuggingFaceEndpoint(
#             repo_id=repo_id,
#             max_length=128,
#             temperature=0.6,
#             stop_sequences=["End of Report"],
#             huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN
#         )
#         template = '''Summarize the following pathology laboratory blood test report. Provide a concise answer based on the available data.
#         Use the following report: {text}
#         Provide a concise answer:
#         '''
#         final = PromptTemplate(template=template, input_variables=['text'])
#         chain = load_summarize_chain(llm, chain_type="map_reduce", combine_prompt=final, verbose=False)
#         summary = chain.invoke(chunks)
#         return summary['output_text']
#     except Exception as e:
#         st.error(f"Error generating summary: {e}")
#         return None

# # Function to create a vector store using Hugging Face embeddings
# def vector_store(chunks):
#     try:
#         embedding_model = HuggingFaceEmbeddings(
#             model_name="sentence-transformers/paraphrase-MiniLM-L6-v2",
#             model_kwargs={"token": HUGGINGFACEHUB_API_TOKEN}
#         )
#         vector_store = FAISS.from_documents(chunks, embedding_model)
#         return vector_store
#     except Exception as e:
#         st.error(f"Error creating vector store: {e}")
#         return None

# # Function to create a retrieval chain for Q&A
# def create_chain(vs, question):
#     try:
#         repo_id = "meta-llama/Meta-Llama-3-8B-Instruct"
#         llm = HuggingFaceEndpoint(
#             repo_id=repo_id,
#             max_length=128,
#             temperature=0.6,
#             stop_sequences=['Answer'],
#             huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN
#         )
#         retriever = VectorStoreRetriever(vectorstore=vs)
#         chain = RetrievalQA.from_chain_type(llm, retriever=retriever)
#         answer = chain({"query": question})
#         return answer['result']
#     except Exception as e:
#         st.error(f"Error creating retrieval chain: {e}")
#         return None

# # Streamlit UI
# st.set_page_config(page_title="Report Summary", page_icon='üë®‚Äç‚öïÔ∏è')
# st.title("Medical Report Diagnosis üë®‚Äç‚öïÔ∏è")

# uploaded_file = st.file_uploader("Add Your Report Here :", type=["jpg", "jpeg", "pdf"])

# if uploaded_file is not None:
#     file_extension = uploaded_file.name.split(".")[-1].lower()

#     if file_extension == "pdf":
#         if "chunks" not in st.session_state:
#             st.session_state.chunks = extract_text_from_pdf(uploaded_file)
#         if "vec_store" not in st.session_state and st.session_state.chunks:
#             st.session_state.vec_store = vector_store(st.session_state.chunks)

#     elif file_extension in ["jpg", "jpeg"]:
#         image = Image.open(uploaded_file)
#         if "chunks" not in st.session_state:
#             st.session_state.chunks = extract_text_from_image(image)
#         if "vec_store" not in st.session_state and st.session_state.chunks:
#             st.session_state.vec_store = vector_store(st.session_state.chunks)

#     with st.sidebar:
#         st.header("Summary : ")
#         if st.button("Summarize Report"):
#             if "chunks" in st.session_state and st.session_state.chunks:
#                 st.session_state.summary = generate_summary(st.session_state.chunks)
#                 if st.session_state.summary:
#                     st.write(st.session_state.summary)
#             else:
#                 st.error("No text chunks available for summarization.")
#         if "summary" in st.session_state:
#             st.write(st.session_state.summary)

#     question = st.chat_input("Ask About Report")
#     if question is not None and question != "":
#         if "vec_store" in st.session_state and st.session_state.vec_store:
#             st.chat_message("user").write(question)
#             answer = create_chain(st.session_state.vec_store, question)
#             if answer:
#                 st.chat_message("assistant").write(answer)
#         else:
#             st.error("Vector store not available. Please upload a valid report.")






















# import streamlit as st
# from dotenv import load_dotenv
# import fitz  # PyMuPDF
# import easyocr
# from PIL import Image
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings
# from langchain_core.prompts import PromptTemplate
# from langchain.chains.summarize import load_summarize_chain
# from langchain_community.vectorstores import FAISS
# from langchain_core.vectorstores import VectorStoreRetriever
# from langchain.chains.retrieval_qa.base import RetrievalQA
# import os

# # Load environment variables
# load_dotenv()

# # Set the Hugging Face token from environment variables
# token = os.getenv("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")
# if token is None:
#     raise ValueError("Hugging Face API token is not set. Please check your .env file.")
# os.environ['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'] = token

# # Initialize the language model
# llm = HuggingFaceEndpoint(repo_id="meta-llama/Meta-Llama-3-8B-Instruct", max_length=128, temperature=0.6, stop_sequences=["End of Report"])

# def extract_text_from_image(image):
#     reader = easyocr.Reader(['en'])
#     result = reader.readtext(image, detail=0)
#     text = "\n".join(result)
#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)
#     chunks = text_splitter.create_documents([text])
#     return chunks

# def extract_text_from_pdf(pdf_file):
#     text = ""
#     pdf_document = fitz.open(stream=pdf_file.read(), filetype="pdf")
#     for page_num in range(pdf_document.page_count):
#         page = pdf_document.load_page(page_num)
#         text += page.get_text()
#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)
#     chunks = text_splitter.create_documents([text])
#     return chunks

# def generate_summary(chunks):
#     template = '''Summarize the following pathology laboratory blood test report. Provide a concise answer based on the available data.
#     Use the following report: {text}
#     Provide a concise answer:'''
    
#     final = PromptTemplate(template=template, input_variables=['text'])
#     chain = load_summarize_chain(llm, chain_type="map_reduce", combine_prompt=final, verbose=False)
    
#     if not chunks:
#         st.error("No chunks available for summarization.")
#         return {"output_text": "No summary available."}
    
#     summary = chain.invoke(chunks)
#     return summary['output_text']

# def vector_store(chunks):
#     embedding_model = HuggingFaceEmbeddings(model_name="paraphrase-MiniLM-L6-v2")
#     # Create FAISS vector store 
#     vector_store = FAISS.from_documents(chunks, embedding_model)
#     return vector_store

# def create_chain(vs, question):
#     retriever = VectorStoreRetriever(vectorstore=vs)
#     chain = RetrievalQA.from_chain_type(llm, retriever=retriever)
    
#     answer = chain({"query": question})
#     return answer['result']

# # Streamlit app configuration
# st.set_page_config(page_title="Report Summary", page_icon='üë®‚Äç‚öïÔ∏è')
# st.title("Medical Report Diagnosis üë®‚Äç‚öïÔ∏è")

# # File uploader
# uploaded_file = st.file_uploader("Add Your Report Here:", type=["jpg", "jpeg", "pdf"])

# if uploaded_file is not None and uploaded_file.size > 0:
#     file_extension = uploaded_file.name.split(".")[-1].lower()
    
#     if file_extension == "pdf":
#         st.session_state.chunks = extract_text_from_pdf(uploaded_file)
#         if st.session_state.chunks is None or len(st.session_state.chunks) == 0:
#             st.error("Failed to extract text from PDF.")
#             st.session_state.chunks = []  # Ensure it's an empty list for further processing
#         else:
#             st.session_state.vec_store = vector_store(st.session_state.chunks)

#     elif file_extension in ["jpg", "jpeg"]:
#         image = Image.open(uploaded_file)
#         st.session_state.chunks = extract_text_from_image(image)
#         if st.session_state.chunks is None or len(st.session_state.chunks) == 0:
#             st.error("Failed to extract text from image.")
#             st.session_state.chunks = []  # Ensure it's an empty list for further processing
#         else:
#             st.session_state.vec_store = vector_store(st.session_state.chunks)

#     with st.sidebar:
#         st.header("Summary:")
#         if st.button("Summarize Report"):
#             if "chunks" in st.session_state and st.session_state.chunks:
#                 st.session_state.summary = generate_summary(st.session_state.chunks)
#                 st.write(st.session_state.summary)
#             else:
#                 st.error("No chunks available for summarization.")

#         if "summary" in st.session_state:
#             st.write(st.session_state.summary)

#     question = st.chat_input("Ask About Report:")
#     if question:
#         st.chat_message("user").write(question)
#         if "vec_store" in st.session_state:
#             answer = create_chain(st.session_state.vec_store, question)
#             st.chat_message("assistant").write(answer)
#         else:
#             st.error("Vector store not available. Please upload a report first.")
